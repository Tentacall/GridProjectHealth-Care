{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing libraries \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from PIL import Image, ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "import cv2\n",
    "\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from functools import partial\n",
    "import scipy as sp\n",
    "\n",
    "import random\n",
    "import time\n",
    "import sys\n",
    "import os\n",
    "import yaml\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import torch\n",
    "import torchvision\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torchvision import transforms, models, datasets\n",
    "from torchvision.models.feature_extraction import create_feature_extractor\n",
    "from torch.utils.data import Dataset\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_path = 'config/preprocessing_config.yaml'\n",
    "conf = yaml.safe_load(open(config_path,'r'))\n",
    "train_image_path = conf['train_dataset']['image_path']\n",
    "test_image_path = conf['test_dataset']['image_path']\n",
    "train_labels_path = conf['train_dataset']['label_path']\n",
    "test_labels_path = conf['test_dataset']['label_path']\n",
    "batch_size = conf['image_preprocessing']['batch_size']\n",
    "shuffle = conf['image_preprocessing']['shuffle']\n",
    "do_random_crop = conf['image_preprocessing']['do_random_crop']\n",
    "columns = conf['image_preprocessing']['columns']\n",
    "image_size = conf['image_preprocessing']['image_size']\n",
    "itype = conf['image_preprocessing']['itype']\n",
    "device = conf['metadata']['device']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.dataloader import load_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GPU CHECK\n",
    "train_on_gpu = torch.cuda.is_available()\n",
    "if not train_on_gpu:\n",
    "    print('CUDA is not available. Training on CPU...')\n",
    "    device = torch.device('cpu')\n",
    "else:\n",
    "    print('CUDA is available. Training on GPU...')\n",
    "    device = torch.device('cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import data\n",
    "train = pd.read_csv(train_labels_path)\n",
    "test = pd.read_csv(test_labels_path)\n",
    "\n",
    "# check shape\n",
    "print(train.shape, test.shape)\n",
    "print('-' * 15)\n",
    "print(train[columns[1]].value_counts())\n",
    "print('-' * 15)\n",
    "print(test[columns[1]].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(load_data))\n",
    "loader = load_data(train_labels_path, test_labels_path, train_image_path, test_image_path, columns, itype = '.jpg', batch_size = 16, shuffle=True, do_random_crop = False, device = 'cpu')\n",
    "train_loader, test_loader, valid_loader = loader.create_loader()\n",
    "for batch_i, data in enumerate(train_loader):\n",
    "    # extract data\n",
    "    inputs = data['image']\n",
    "    print(inputs.shape)\n",
    "    labels = data['label'].view(-1, 1)\n",
    "    # labels = data['label'].view(-1, 1)\n",
    "    \n",
    "    # create plot\n",
    "    fig = plt.figure(figsize = (20,10))\n",
    "    for i in range(len(labels)):\n",
    "        ax = fig.add_subplot(2, int(len(labels)/2), i + 1, xticks = [], yticks = [])     \n",
    "        plt.imshow(inputs[i].numpy().transpose(1, 2, 0))\n",
    "        ax.set_title(labels.numpy()[i])\n",
    "        \n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# baseModel = torchvision.models.efficientnet_b7(pretrained=True)\n",
    "# x = torch.rand(1, 3, 224, 224)\n",
    "# train_nodes, eval_nodes = torchvision.models.feature_extraction.get_graph_node_names(baseModel)\n",
    "# print(train_nodes)\n",
    "# print(eval_nodes)\n",
    "# return_nodes = conf['model']['return_nodes']\n",
    "# model = create_feature_extractor(baseModel, return_nodes)\n",
    "# y = model(x)\n",
    "# print(y[return_nodes[0]].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_tensor = []\n",
    "# for batch_i, data in enumerate(sample_train_loader):\n",
    "#     # extract data\n",
    "#     inputs = data['image']\n",
    "#     print(inputs.shape)\n",
    "#     y_pred = model(inputs)\n",
    "#     print(y_pred[return_nodes[0]].shape)\n",
    "#     train_tensor.append(y_pred[return_nodes[0]])\n",
    "#     labels = data['label'].view(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(y_true, y_pred):\n",
    "    \n",
    "    # Intitializing variable to store count of correctly predicted classes\n",
    "    correct_predictions = 0\n",
    "    \n",
    "    for yt, yp in zip(y_true, y_pred):\n",
    "        \n",
    "        if yt == yp:\n",
    "            \n",
    "            correct_predictions += 1\n",
    "    \n",
    "    #returns accuracy\n",
    "    return correct_predictions / len(y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassificationBase(nn.Module):\n",
    "    \n",
    "    def training_step(self, batch):\n",
    "        images, labels = batch['image'], batch['label']\n",
    "        out = self(images)                  # Generate predictions\n",
    "        loss = F.cross_entropy(out, labels) # Calculate loss\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch):\n",
    "        images, labels = batch['image'], batch['label'] \n",
    "        out = self(images)                    # Generate predictions\n",
    "        loss = F.cross_entropy(out, labels)   # Calculate loss\n",
    "        acc = accuracy(out, labels)           # Calculate accuracy\n",
    "        return {'val_loss': loss.detach(), 'val_acc': acc}\n",
    "        \n",
    "    def validation_epoch_end(self, outputs):\n",
    "        batch_losses = [x['val_loss'] for x in outputs]\n",
    "        epoch_loss = torch.stack(batch_losses).mean()   # Combine losses\n",
    "        batch_accs = [x['val_acc'] for x in outputs]\n",
    "        epoch_acc = torch.stack(batch_accs).mean()      # Combine accuracies\n",
    "        return {'val_loss': epoch_loss.item(), 'val_acc': epoch_acc.item()}\n",
    "    \n",
    "    def epoch_end(self, epoch, result):\n",
    "        print(\"Epoch [{}], train_loss: {:.4f}, val_loss: {:.4f}, val_acc: {:.4f}\".format(\n",
    "            epoch, result['train_loss'], result['val_loss'], result['val_acc']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "            # nn.Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
    "            # nn.ReLU(inplace=True),\n",
    "            # nn.Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
    "            # nn.ReLU(inplace=True),\n",
    "            # nn.MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False),\n",
    "            \n",
    "            # nn.Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
    "            # nn.ReLU(inplace=True),\n",
    "            # nn.Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
    "            # nn.ReLU(inplace=True),\n",
    "            # nn.MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False),\n",
    "            \n",
    "            # nn.Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
    "            # nn.ReLU(inplace=True),\n",
    "            # nn.Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
    "            # nn.ReLU(inplace=True),\n",
    "            # nn.Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
    "            # nn.ReLU(inplace=True),\n",
    "            # nn.MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False),\n",
    "            \n",
    "            # nn.Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
    "            # nn.ReLU(inplace=True),\n",
    "            # nn.Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
    "            # nn.ReLU(inplace=True),\n",
    "            # nn.Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
    "            # nn.ReLU(inplace=True),\n",
    "            # nn.MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False),\n",
    "            \n",
    "            # nn.Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
    "            # nn.ReLU(inplace=True),\n",
    "            # nn.Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
    "            # nn.ReLU(inplace=True),\n",
    "            # nn.Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
    "            # nn.ReLU(inplace=True),\n",
    "            # nn.MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
    "            \n",
    "            # nn.AdaptiveAvgPool2d(output_size=(7, 7))\n",
    "            \n",
    "            # nn.Linear(in_features=25088, out_features=4096, bias=True),\n",
    "            # nn.ReLU(inplace=True),\n",
    "            # nn.Dropout(p=0.5, inplace=False),\n",
    "            # nn.Linear(in_features=4096, out_features=4096, bias=True),\n",
    "            # nn.ReLU(inplace=True),\n",
    "            # nn.Dropout(p=0.5, inplace=False),\n",
    "            # nn.Linear(in_features=4096, out_features=1000, bias=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RetinopathyClassification(ClassificationBase):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            \n",
    "            nn.Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False),\n",
    "        \n",
    "            nn.Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False),\n",
    "            \n",
    "            nn.Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False),\n",
    "            \n",
    "            nn.Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False),\n",
    "            \n",
    "            nn.Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
    "        )\n",
    "        \n",
    "        self.avgpool = nn.Sequential(\n",
    "                      \n",
    "            nn.AdaptiveAvgPool2d(output_size=(7, 7))\n",
    "        )\n",
    "    \n",
    "        self.classifier = nn.Sequential(\n",
    "            \n",
    "            nn.Flatten(),  \n",
    "            nn.Linear(in_features=25088, out_features=4096, bias=True),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(p=0.5, inplace=False),\n",
    "            nn.Linear(in_features=4096, out_features=4096, bias=True),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(p=0.5, inplace=False),\n",
    "            nn.Linear(in_features=4096, out_features=1000, bias=True)\n",
    "        )\n",
    "        \n",
    "        self.overall = nn.Sequential(\n",
    "                      \n",
    "            self.features,\n",
    "            self.avgpool,\n",
    "            self.classifier\n",
    "        )\n",
    "        \n",
    "    def forward(self, xb):\n",
    "        \n",
    "        self.out = self.overall(xb)\n",
    "        return self.out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def evaluate(model, val_loader):\n",
    "    model.eval()\n",
    "    outputs = [model.validation_step(batch) for batch in val_loader]\n",
    "    return model.validation_epoch_end(outputs)\n",
    "\n",
    "  \n",
    "def fit(epochs, lr, model, train_loader, val_loader, opt_func = torch.optim.SGD):\n",
    "    \n",
    "    history = []\n",
    "    optimizer = opt_func(model.parameters(),lr)\n",
    "    for epoch in range(epochs):\n",
    "        \n",
    "        model.train()\n",
    "        train_losses = []\n",
    "        for batch in train_loader:\n",
    "            loss = model.training_step(batch)\n",
    "            train_losses.append(loss)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "        result = evaluate(model, val_loader)\n",
    "        result['train_loss'] = torch.stack(train_losses).mean().item()\n",
    "        model.epoch_end(epoch, result)\n",
    "        history.append(result)\n",
    "    \n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(train_loader.data.shape)\n",
    "# print(test_loader.data.shape)\n",
    "# print(valid_loader.data.shape)\n",
    "count = 0\n",
    "for batch in train_loader:\n",
    "    print(batch['image'].shape)\n",
    "    print(batch['label'].shape)\n",
    "    count = count+1\n",
    "print(count)\n",
    "count=0\n",
    "for batch in test_loader:\n",
    "    print(batch['image'].shape)\n",
    "    print(batch['label'].shape)\n",
    "    count=count+1\n",
    "print(count)\n",
    "count=0\n",
    "for batch in valid_loader:\n",
    "    print(batch['image'].shape)\n",
    "    print(batch['label'].shape)\n",
    "    count=count+1\n",
    "print(count)\n",
    "count=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
