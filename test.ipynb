{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dir(nn.Module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing libraries \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from PIL import Image, ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "import cv2\n",
    "\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from functools import partial\n",
    "import scipy as sp\n",
    "\n",
    "import random\n",
    "import time\n",
    "import sys\n",
    "import os\n",
    "import yaml\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import torch\n",
    "import torchvision\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torchvision import transforms, models, datasets\n",
    "from torchvision.models.feature_extraction import create_feature_extractor\n",
    "from torch.utils.data import Dataset\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available. Training on GPU...\n"
     ]
    }
   ],
   "source": [
    "train_on_gpu = torch.cuda.is_available()\n",
    "if not train_on_gpu:\n",
    "    print('CUDA is not available. Training on CPU...')\n",
    "    device = torch.device('cpu')\n",
    "else:\n",
    "    print('CUDA is available. Training on GPU...')\n",
    "    device = torch.device('cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_path = 'config/preprocessing_config.yaml'\n",
    "conf = yaml.safe_load(open(config_path,'r'))\n",
    "train_image_path = conf['train_dataset']['image_path']\n",
    "test_image_path = conf['test_dataset']['image_path']\n",
    "train_labels_path = conf['train_dataset']['label_path']\n",
    "test_labels_path = conf['test_dataset']['label_path']\n",
    "batch_size = conf['image_preprocessing']['batch_size']\n",
    "shuffle = conf['image_preprocessing']['shuffle']\n",
    "do_random_crop = conf['image_preprocessing']['do_random_crop']\n",
    "columns = conf['image_preprocessing']['columns']\n",
    "image_size = conf['image_preprocessing']['image_size']\n",
    "itype = conf['image_preprocessing']['itype']\n",
    "device = conf['metadata']['device']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.dataloader import load_data\n",
    "from utils.functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(413, 12) (103, 3)\n",
      "---------------\n",
      "Retinopathy grade\n",
      "2    136\n",
      "0    134\n",
      "3     74\n",
      "4     49\n",
      "1     20\n",
      "Name: count, dtype: int64\n",
      "---------------\n",
      "Retinopathy grade\n",
      "0    34\n",
      "2    32\n",
      "3    19\n",
      "4    13\n",
      "1     5\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# import data\n",
    "train = pd.read_csv(train_labels_path)\n",
    "test = pd.read_csv(test_labels_path)\n",
    "\n",
    "# check shape\n",
    "print(train.shape, test.shape)\n",
    "print('-' * 15)\n",
    "print(train[columns[1]].value_counts())\n",
    "print('-' * 15)\n",
    "print(test[columns[1]].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = load_data(train_labels_path, test_labels_path, train_image_path, test_image_path, columns, itype = '.jpg', batch_size = 16, shuffle=True, do_random_crop = False, device = 'cpu')\n",
    "train_loader, test_loader, valid_loader = loader.create_loader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count = 0\n",
    "# for batch in train_loader:\n",
    "#     print(batch['image'].shape)\n",
    "#     print(batch['label'].shape)\n",
    "#     count = count+1\n",
    "# print(count)\n",
    "# count=0\n",
    "# for batch in test_loader:\n",
    "#     print(batch['image'].shape)\n",
    "#     print(batch['label'].shape)\n",
    "#     count=count+1\n",
    "# print(count)\n",
    "# count=0\n",
    "# for batch in valid_loader:\n",
    "#     print(batch['image'].shape)\n",
    "#     print(batch['label'].shape)\n",
    "#     count=count+1\n",
    "# print(count)\n",
    "# count=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Image name  Retinopathy grade\n",
      "51  IDRiD_052                  0\n",
      "52  IDRiD_053                  4\n",
      "53  IDRiD_054                  0\n",
      "54  IDRiD_055                  0\n",
      "55  IDRiD_056                  0\n"
     ]
    }
   ],
   "source": [
    "print(loader.valid_df.iloc[:5, 0:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RetinopathyClassification(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            \n",
    "            nn.Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False),\n",
    "        \n",
    "            nn.Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False),\n",
    "            \n",
    "            nn.Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
    "            nn.ReLU(inplace=True),\n",
    "            # nn.Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
    "            # nn.ReLU(inplace=True),\n",
    "            # nn.Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
    "            # nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False),\n",
    "            \n",
    "            nn.Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
    "            nn.ReLU(inplace=True),\n",
    "            # nn.Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
    "            # nn.ReLU(inplace=True),\n",
    "            # nn.Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
    "            # nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False),\n",
    "            \n",
    "            nn.Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
    "            nn.ReLU(inplace=True),\n",
    "            # nn.Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
    "            # nn.ReLU(inplace=True),\n",
    "            # nn.Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
    "            # nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
    "        )\n",
    "        \n",
    "        self.avgpool = nn.Sequential(\n",
    "                      \n",
    "            nn.AdaptiveAvgPool2d(output_size=(7, 7))\n",
    "        )\n",
    "    \n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),  \n",
    "            nn.Linear(in_features=25088, out_features=4096, bias=True),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(p=0.5, inplace=False),\n",
    "            nn.Linear(in_features=4096, out_features=4096, bias=True),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(p=0.5, inplace=False),\n",
    "            nn.Linear(in_features=4096, out_features=1000, bias=True),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(in_features=1000, out_features=5, bias=True),\n",
    "            nn.Softmax()\n",
    "        )\n",
    "        \n",
    "        self.overall = nn.Sequential(\n",
    "            self.features,\n",
    "            self.avgpool,\n",
    "            self.classifier\n",
    "        )\n",
    "        \n",
    "    def forward(self, xb):\n",
    "        \n",
    "        self.out = self.overall(xb)\n",
    "        return self.out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCannot execute code, session has been disposed. Please try restarting the Kernel."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "lr = 1e-4\n",
    "model = RetinopathyClassification().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(epochs, lr, model, train_loader, opt_func = torch.optim.Adam):\n",
    "    \n",
    "    history = []\n",
    "    optimizer = opt_func(model.parameters(),lr)\n",
    "    for epoch in range(epochs):\n",
    "        \n",
    "        model.train()\n",
    "        result = {'train_loss': [], 'train_acc': []}\n",
    "        train_losses = []\n",
    "        train_accuracy = []\n",
    "        for batch in train_loader:\n",
    "            images, labels = batch['image'], batch['label']\n",
    "            optimizer.zero_grad()\n",
    "            out = model(images)                  # Generate predictions\n",
    "            loss = ordinal_loss(out, labels) # Calculate loss\n",
    "            train_losses.append(loss)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            acc = ordinal_accuracy(out, labels)\n",
    "            train_accuracy.append(acc)\n",
    "            print(\"Epoch [{}], Batch [{}], train_loss: {:.4f}, train_acc: {:.4f}, val_acc: {:.4f}\".format(\n",
    "            epoch, batch, loss.detach(), acc.detach()), flush=True)\n",
    "            result['train_loss'].append(loss.detach())\n",
    "            result['train_acc'].append(acc.detach())\n",
    "            \n",
    "        result['train_loss'] = torch.stack(train_losses).mean().item()\n",
    "        result['train_acc'] = torch.stack(train_accuracy).mean().item()\n",
    "        print(\"Epoch [{}], train_loss: {:.4f}, train_acc: {:.4f}, val_acc: {:.4f}\".format(\n",
    "            epoch, result['train_loss'], result['train_acc']))\n",
    "        history.append(result)\n",
    "    \n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "output with shape [] doesn't match the broadcast shape [16]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m fit(epochs, lr, model, train_loader)\n",
      "Cell \u001b[0;32mIn[13], line 15\u001b[0m, in \u001b[0;36mfit\u001b[0;34m(epochs, lr, model, train_loader, opt_func)\u001b[0m\n\u001b[1;32m     13\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[1;32m     14\u001b[0m out \u001b[39m=\u001b[39m model(images)                  \u001b[39m# Generate predictions\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m loss \u001b[39m=\u001b[39m ordinal_loss(out, labels) \u001b[39m# Calculate loss\u001b[39;00m\n\u001b[1;32m     16\u001b[0m train_losses\u001b[39m.\u001b[39mappend(loss)\n\u001b[1;32m     17\u001b[0m loss\u001b[39m.\u001b[39mbackward()\n",
      "File \u001b[0;32m~/github/GridProjectHealth-Care/utils/functions.py:13\u001b[0m, in \u001b[0;36mordinal_loss\u001b[0;34m(y_pred, y_true, num_classes)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(num_classes \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m):\n\u001b[1;32m     12\u001b[0m     loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mlog(torch\u001b[39m.\u001b[39mexp(y_pred[:, i]) \u001b[39m+\u001b[39m \u001b[39m1e-10\u001b[39m)\u001b[39m.\u001b[39msum() \u001b[39m-\u001b[39m y_pred[:, i \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m]\u001b[39m.\u001b[39msum()\n\u001b[0;32m---> 13\u001b[0m     loss \u001b[39m*\u001b[39m\u001b[39m=\u001b[39m (y_true \u001b[39m>\u001b[39m i)\u001b[39m.\u001b[39mfloat()\n\u001b[1;32m     14\u001b[0m loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mlog(torch\u001b[39m.\u001b[39mexp(y_pred[:, num_classes \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m]) \u001b[39m+\u001b[39m \u001b[39m1e-10\u001b[39m)\u001b[39m.\u001b[39msum()\n\u001b[1;32m     15\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39m-\u001b[39mloss\u001b[39m.\u001b[39mmean()\n",
      "\u001b[0;31mRuntimeError\u001b[0m: output with shape [] doesn't match the broadcast shape [16]"
     ]
    }
   ],
   "source": [
    "fit(epochs, lr, model, train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
