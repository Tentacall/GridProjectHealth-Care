{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.optim as optim\n",
    "from utils.dataloader  import load_data\n",
    "import time\n",
    "from utils.confLoader import *\n",
    "from models.qcModel import Quanv2D\n",
    "import qsimcirq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9912422/9912422 [00:11<00:00, 853882.39it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28881/28881 [00:00<00:00, 1305862.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1648877/1648877 [00:03<00:00, 530873.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4542/4542 [00:00<00:00, 38563823.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "batch_size = 16  # You can adjust this based on your needs\n",
    "\n",
    "train_dataset = torchvision.datasets.MNIST(root='./data', train=True, transform=transform, download=True)\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "test_dataset = torchvision.datasets.MNIST(root='./data', train=False, transform=transform, download=True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "# Check if CUDA (GPU) is available\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    \n",
    "print(device)\n",
    "\n",
    "# Example of moving a tensor to the specified device\n",
    "tensor = torch.tensor([1.0, 2.0, 3.0])\n",
    "tensor = tensor.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleModel(nn.Module):\n",
    "    def __init__(self, *args, **kwargs) -> None:\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.simulator = qsimcirq.QSimSimulator()\n",
    "        self.features = nn.Sequential(\n",
    "            Quanv2D(self.simulator, 1, 28, kernel_size=2, stride = 1), # 27*27\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride = 2), #13*13\n",
    "            nn.Conv2d(28, 196, kernel_size=2, stride = 1), #10*10\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride = 2), #6*6\n",
    "        )\n",
    "        \n",
    "        self.avgpool = nn.Sequential(\n",
    "            nn.AdaptiveAvgPool2d(output_size=(6*6))\n",
    "        )\n",
    "        \n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(in_features=196*6*6, out_features=250, bias=True),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(p=0.5, inplace=False),\n",
    "            nn.Linear(in_features=250, out_features=10, bias=True)\n",
    "        )\n",
    "        \n",
    "        self.overall = nn.Sequential(             \n",
    "            self.features,\n",
    "            self.avgpool,\n",
    "            self.classifier\n",
    "        )\n",
    "        \n",
    "        def backward(self, *args, **kwargs):\n",
    "            print(\"Custom backward function called\")\n",
    "            super().backward(*args, **kwargs)\n",
    "        \n",
    "    def forward(self, xb):\n",
    "        self.out = self.overall(xb)\n",
    "        return self.out\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SimpleModel(\n",
      "  (features): Sequential(\n",
      "    (0): Quanv2D( 1, 28, kernel =(2,2) stride =(1, 1), precision=10 )\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (3): Conv2d(28, 196, kernel_size=(2, 2), stride=(1, 1))\n",
      "    (4): ReLU(inplace=True)\n",
      "    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (avgpool): Sequential(\n",
      "    (0): AdaptiveAvgPool2d(output_size=36)\n",
      "  )\n",
      "  (classifier): Sequential(\n",
      "    (0): Flatten(start_dim=1, end_dim=-1)\n",
      "    (1): Linear(in_features=7056, out_features=250, bias=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): Dropout(p=0.5, inplace=False)\n",
      "    (4): Linear(in_features=250, out_features=10, bias=True)\n",
      "  )\n",
      "  (overall): Sequential(\n",
      "    (0): Sequential(\n",
      "      (0): Quanv2D( 1, 28, kernel =(2,2) stride =(1, 1), precision=10 )\n",
      "      (1): ReLU(inplace=True)\n",
      "      (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (3): Conv2d(28, 196, kernel_size=(2, 2), stride=(1, 1))\n",
      "      (4): ReLU(inplace=True)\n",
      "      (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    )\n",
      "    (1): Sequential(\n",
      "      (0): AdaptiveAvgPool2d(output_size=36)\n",
      "    )\n",
      "    (2): Sequential(\n",
      "      (0): Flatten(start_dim=1, end_dim=-1)\n",
      "      (1): Linear(in_features=7056, out_features=250, bias=True)\n",
      "      (2): ReLU(inplace=True)\n",
      "      (3): Dropout(p=0.5, inplace=False)\n",
      "      (4): Linear(in_features=250, out_features=10, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = SimpleModel()\n",
    "model = model.to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "a leaf Variable that requires grad is being used in an in-place operation.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[42], line 12\u001b[0m\n\u001b[1;32m     10\u001b[0m total_image \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m inputs\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]\n\u001b[1;32m     11\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[0;32m---> 12\u001b[0m outputs \u001b[39m=\u001b[39m model(inputs)\n\u001b[1;32m     13\u001b[0m loss \u001b[39m=\u001b[39m criterion(outputs, labels)\n\u001b[1;32m     14\u001b[0m loss\u001b[39m.\u001b[39mbackward()\n",
      "File \u001b[0;32m~/github/GridProjectHealth-Care/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn[40], line 37\u001b[0m, in \u001b[0;36mSimpleModel.forward\u001b[0;34m(self, xb)\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, xb):\n\u001b[0;32m---> 37\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mout \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moverall(xb)\n\u001b[1;32m     38\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mout\n",
      "File \u001b[0;32m~/github/GridProjectHealth-Care/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/github/GridProjectHealth-Care/venv/lib/python3.10/site-packages/torch/nn/modules/container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[1;32m    216\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[0;32m--> 217\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[1;32m    218\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[0;32m~/github/GridProjectHealth-Care/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/github/GridProjectHealth-Care/venv/lib/python3.10/site-packages/torch/nn/modules/container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[1;32m    216\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[0;32m--> 217\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[1;32m    218\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[0;32m~/github/GridProjectHealth-Care/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/github/GridProjectHealth-Care/venv/lib/python3.10/site-packages/torch/nn/modules/activation.py:103\u001b[0m, in \u001b[0;36mReLU.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 103\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mrelu(\u001b[39minput\u001b[39;49m, inplace\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minplace)\n",
      "File \u001b[0;32m~/github/GridProjectHealth-Care/venv/lib/python3.10/site-packages/torch/nn/functional.py:1455\u001b[0m, in \u001b[0;36mrelu\u001b[0;34m(input, inplace)\u001b[0m\n\u001b[1;32m   1453\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(relu, (\u001b[39minput\u001b[39m,), \u001b[39minput\u001b[39m, inplace\u001b[39m=\u001b[39minplace)\n\u001b[1;32m   1454\u001b[0m \u001b[39mif\u001b[39;00m inplace:\n\u001b[0;32m-> 1455\u001b[0m     result \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mrelu_(\u001b[39minput\u001b[39;49m)\n\u001b[1;32m   1456\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1457\u001b[0m     result \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mrelu(\u001b[39minput\u001b[39m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: a leaf Variable that requires grad is being used in an in-place operation."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# model = model.to(device)\n",
    "total_loss = 0\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "total_image  = 0\n",
    "for epoch in range(100):\n",
    "    running_loss = 0.0\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        total_image += inputs.shape[0]\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        if total_image > 300 : break\n",
    "    print(f\"Epoch {epoch+1}, Loss: {running_loss / len(train_loader)}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1888\n"
     ]
    }
   ],
   "source": [
    "print(total_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 112 test images: 62.50%\n"
     ]
    }
   ],
   "source": [
    "total = 0\n",
    "correct = 0\n",
    "num_images = 0\n",
    "for inputs, labels in test_loader:\n",
    "    inputs, labels = inputs.to(device), labels.to(device)\n",
    "    outputs = model(inputs)\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    total += labels.size(0)\n",
    "    # print(outputs, labels)\n",
    "    correct += (predicted == labels).sum().item()\n",
    "    num_images += inputs.size(0)\n",
    "    if num_images > 100: break\n",
    "    # print(f\"total: {total}, correct = {correct}\")\n",
    "print(f'Accuracy of the network on the {total} test images: {100 * correct / total:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from train import Trainner\n",
    "from models.model_v2 import RetinopathyClassification\n",
    "import torch.multiprocessing as mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total: 4, correct = 0\n",
      "total: 8, correct = 1\n",
      "total: 12, correct = 5\n",
      "total: 16, correct = 6\n",
      "total: 20, correct = 9\n",
      "total: 24, correct = 11\n",
      "total: 28, correct = 12\n",
      "total: 32, correct = 12\n",
      "total: 36, correct = 13\n",
      "total: 40, correct = 13\n",
      "total: 44, correct = 13\n",
      "total: 48, correct = 14\n",
      "total: 52, correct = 16\n",
      "total: 56, correct = 16\n",
      "total: 60, correct = 17\n",
      "total: 64, correct = 17\n",
      "total: 68, correct = 19\n",
      "total: 72, correct = 20\n",
      "total: 76, correct = 21\n",
      "total: 80, correct = 22\n",
      "total: 84, correct = 26\n",
      "total: 88, correct = 28\n",
      "total: 92, correct = 30\n",
      "total: 96, correct = 30\n",
      "total: 100, correct = 31\n",
      "Accuracy of the network on the 100 test images: 31.00%\n",
      "tensor([[2., 2., 2., 2.],\n",
      "        [2., 2., 2., 2.],\n",
      "        [2., 2., 2., 2.],\n",
      "        [2., 2., 2., 2.],\n",
      "        [2., 2., 2., 2.],\n",
      "        [2., 2., 2., 2.],\n",
      "        [2., 2., 2., 2.],\n",
      "        [2., 2., 2., 2.],\n",
      "        [2., 2., 2., 2.],\n",
      "        [2., 2., 2., 2.],\n",
      "        [2., 2., 2., 2.],\n",
      "        [2., 2., 2., 2.],\n",
      "        [2., 2., 2., 2.],\n",
      "        [2., 2., 2., 2.],\n",
      "        [2., 2., 2., 2.],\n",
      "        [2., 2., 2., 2.],\n",
      "        [2., 2., 2., 2.],\n",
      "        [2., 2., 2., 2.],\n",
      "        [2., 2., 2., 2.],\n",
      "        [2., 2., 2., 2.],\n",
      "        [2., 2., 2., 2.],\n",
      "        [2., 2., 2., 2.],\n",
      "        [2., 2., 2., 2.],\n",
      "        [2., 2., 2., 2.],\n",
      "        [2., 2., 2., 2.]]) tensor([[4., 4., 4., 4.],\n",
      "        [4., 3., 3., 2.],\n",
      "        [2., 2., 2., 2.],\n",
      "        [3., 3., 2., 3.],\n",
      "        [2., 3., 2., 2.],\n",
      "        [3., 3., 2., 2.],\n",
      "        [3., 3., 3., 2.],\n",
      "        [0., 0., 3., 4.],\n",
      "        [2., 3., 3., 3.],\n",
      "        [0., 0., 0., 4.],\n",
      "        [0., 3., 0., 0.],\n",
      "        [0., 2., 0., 4.],\n",
      "        [2., 0., 2., 0.],\n",
      "        [4., 0., 0., 0.],\n",
      "        [4., 0., 2., 3.],\n",
      "        [4., 4., 1., 3.],\n",
      "        [2., 3., 2., 0.],\n",
      "        [0., 0., 0., 2.],\n",
      "        [1., 1., 0., 2.],\n",
      "        [0., 0., 2., 0.],\n",
      "        [2., 2., 2., 2.],\n",
      "        [1., 2., 4., 2.],\n",
      "        [2., 0., 2., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 2.]])\n",
      "flag\n",
      "torch.Size([100]) torch.Size([100])\n",
      "Metrics for Class 0:\n",
      "Recall: 0.0000\n",
      "Precision: 0.0000\n",
      "F1-score: 0.0000\n",
      "\n",
      "Metrics for Class 1:\n",
      "Recall: 0.0000\n",
      "Precision: 0.0000\n",
      "F1-score: 0.0000\n",
      "\n",
      "Metrics for Class 2:\n",
      "Recall: 1.0000\n",
      "Precision: 0.3100\n",
      "F1-score: 0.4733\n",
      "\n",
      "Metrics for Class 3:\n",
      "Recall: 0.0000\n",
      "Precision: 0.0000\n",
      "F1-score: 0.0000\n",
      "\n",
      "Metrics for Class 4:\n",
      "Recall: 0.0000\n",
      "Precision: 0.0000\n",
      "F1-score: 0.0000\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "mp.set_start_method('spawn')\n",
    "model = RetinopathyClassification()\n",
    "# print(model)\n",
    "trainer = Trainner(model, 20)\n",
    "trainer.loadModel(\"model_classic_v2.5\")\n",
    "# trainer.train()\n",
    "# trainer.save(\"model_resnet_v1.3\")\n",
    "# trainer.test()\n",
    "trainer.conf_mat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import qiskit\n",
    "from qiskit_aer import AerSimulator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qiskit.converters import circuit_to_dag\n",
    "from qiskit.tools.visualization import dag_drawer\n",
    "from qiskit import QuantumRegister, ClassicalRegister, QuantumCircuit\n",
    "from numpy import pi\n",
    "from qiskit import transpile\n",
    "# Use AerSimulator\n",
    "from qiskit_aer import AerSimulator\n",
    "# from qiskit.providers.fake_provider import FakeManilaV2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kernel(P, W):\n",
    "    qreg_q = QuantumRegister(6, 'q')\n",
    "    creg_c = ClassicalRegister(1, 'c')\n",
    "    circuit = QuantumCircuit(qreg_q, creg_c)\n",
    "\n",
    "    for i in range(1,5):\n",
    "        circuit.ry(pi * P[i-1], qreg_q[i])\n",
    "\n",
    "    for i in range(4):\n",
    "        circuit.rx(pi * W[i], qreg_q[0])\n",
    "        circuit.ccx(qreg_q[0], qreg_q[i+1], qreg_q[5])\n",
    "\n",
    "    circuit.measure(qreg_q[5], creg_c[0])\n",
    "\n",
    "    return circuit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# circ = kernel([0.3,0.2,0.1,0.0],[0.3,0.8,0.9,0.2])\n",
    "# aersim = AerSimulator()\n",
    "# backend = FakeManilaV2()\n",
    "# backend = AerSimulator.from_backend(backend)\n",
    "backend = AerSimulator(device = 'GPU', method = \"State Vector\")\n",
    "# simulator = qsimcirq.QSimSimulator()\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loading_bar( current_value, total_value, bar_length=40):\n",
    "    progress = min(1.0, current_value / total_value)\n",
    "    arrow = '■' * int(progress * bar_length)\n",
    "    spaces = ' ' * (bar_length - len(arrow))\n",
    "    print(f'\\r[{arrow}{spaces}] {int(progress * 100)}%', end='', flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def runner():\n",
    "    for i in range(28*28):\n",
    "        circ = kernel([0.3,0.2,0.1,0.0],[0.3,0.8,0.9,0.2])\n",
    "        qc_compiled = transpile(circ, backend)\n",
    "        job_sim = backend.run(qc_compiled, shots=1024)\n",
    "        result_sim = job_sim.result()\n",
    "        counts = result_sim.get_counts(qc_compiled)\n",
    "        loading_bar(i, 28*28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Simulation device \"GPU\" is not supported on this system",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m then \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[0;32m----> 2\u001b[0m runner()\n\u001b[1;32m      3\u001b[0m delta \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m then\n\u001b[1;32m      4\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mImage processed in: \u001b[39m\u001b[39m{\u001b[39;00mdelta\u001b[39m:\u001b[39;00m\u001b[39m .6f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39msec\u001b[39m\u001b[39m\"\u001b[39m) \n",
      "Cell \u001b[0;32mIn[28], line 6\u001b[0m, in \u001b[0;36mrunner\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m qc_compiled \u001b[39m=\u001b[39m transpile(circ, backend)\n\u001b[1;32m      5\u001b[0m job_sim \u001b[39m=\u001b[39m backend\u001b[39m.\u001b[39mrun(qc_compiled, shots\u001b[39m=\u001b[39m\u001b[39m1024\u001b[39m)\n\u001b[0;32m----> 6\u001b[0m result_sim \u001b[39m=\u001b[39m job_sim\u001b[39m.\u001b[39;49mresult()\n\u001b[1;32m      7\u001b[0m counts \u001b[39m=\u001b[39m result_sim\u001b[39m.\u001b[39mget_counts(qc_compiled)\n\u001b[1;32m      8\u001b[0m loading_bar(i, \u001b[39m28\u001b[39m\u001b[39m*\u001b[39m\u001b[39m28\u001b[39m)\n",
      "File \u001b[0;32m~/github/GridProjectHealth-Care/venv/lib/python3.10/site-packages/qiskit_aer/jobs/utils.py:42\u001b[0m, in \u001b[0;36mrequires_submit.<locals>._wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_future \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m     41\u001b[0m     \u001b[39mraise\u001b[39;00m JobError(\u001b[39m\"\u001b[39m\u001b[39mJob not submitted yet!. You have to .submit() first!\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> 42\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/github/GridProjectHealth-Care/venv/lib/python3.10/site-packages/qiskit_aer/jobs/aerjob.py:114\u001b[0m, in \u001b[0;36mAerJob.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[39m@requires_submit\u001b[39m\n\u001b[1;32m     97\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mresult\u001b[39m(\u001b[39mself\u001b[39m, timeout\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m     98\u001b[0m     \u001b[39m# pylint: disable=arguments-differ\u001b[39;00m\n\u001b[1;32m     99\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Get job result. The behavior is the same as the underlying\u001b[39;00m\n\u001b[1;32m    100\u001b[0m \u001b[39m    concurrent Future objects,\u001b[39;00m\n\u001b[1;32m    101\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[39m        concurrent.futures.CancelledError: if job cancelled before completed.\u001b[39;00m\n\u001b[1;32m    113\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 114\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_future\u001b[39m.\u001b[39;49mresult(timeout\u001b[39m=\u001b[39;49mtimeout)\n",
      "File \u001b[0;32m/usr/lib/python3.10/concurrent/futures/_base.py:458\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[39mraise\u001b[39;00m CancelledError()\n\u001b[1;32m    457\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39m==\u001b[39m FINISHED:\n\u001b[0;32m--> 458\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m__get_result()\n\u001b[1;32m    459\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    460\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTimeoutError\u001b[39;00m()\n",
      "File \u001b[0;32m/usr/lib/python3.10/concurrent/futures/_base.py:403\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    401\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exception:\n\u001b[1;32m    402\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 403\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exception\n\u001b[1;32m    404\u001b[0m     \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    405\u001b[0m         \u001b[39m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[1;32m    406\u001b[0m         \u001b[39mself\u001b[39m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m/usr/lib/python3.10/concurrent/futures/thread.py:58\u001b[0m, in \u001b[0;36m_WorkItem.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 58\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfn(\u001b[39m*\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mkwargs)\n\u001b[1;32m     59\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m exc:\n\u001b[1;32m     60\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfuture\u001b[39m.\u001b[39mset_exception(exc)\n",
      "File \u001b[0;32m~/github/GridProjectHealth-Care/venv/lib/python3.10/site-packages/qiskit_aer/backends/aerbackend.py:453\u001b[0m, in \u001b[0;36mAerBackend._execute_circuits_job\u001b[0;34m(self, circuits, parameter_binds, run_options, job_id, format_result)\u001b[0m\n\u001b[1;32m    448\u001b[0m \u001b[39m# Run simulation\u001b[39;00m\n\u001b[1;32m    449\u001b[0m metadata_map \u001b[39m=\u001b[39m {\n\u001b[1;32m    450\u001b[0m     aer_circuit\u001b[39m.\u001b[39mcirc_id: circuit\u001b[39m.\u001b[39mmetadata\n\u001b[1;32m    451\u001b[0m     \u001b[39mfor\u001b[39;00m aer_circuit, circuit \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(aer_circuits, circuits)\n\u001b[1;32m    452\u001b[0m }\n\u001b[0;32m--> 453\u001b[0m output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_execute_circuits(aer_circuits, noise_model, config)\n\u001b[1;32m    455\u001b[0m \u001b[39m# Validate output\u001b[39;00m\n\u001b[1;32m    456\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(output, \u001b[39mdict\u001b[39m):\n",
      "File \u001b[0;32m~/github/GridProjectHealth-Care/venv/lib/python3.10/site-packages/qiskit_aer/backends/aer_simulator.py:835\u001b[0m, in \u001b[0;36mAerSimulator._execute_circuits\u001b[0;34m(self, aer_circuits, noise_model, config)\u001b[0m\n\u001b[1;32m    833\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_execute_circuits\u001b[39m(\u001b[39mself\u001b[39m, aer_circuits, noise_model, config):\n\u001b[1;32m    834\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Execute circuits on the backend.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 835\u001b[0m     ret \u001b[39m=\u001b[39m cpp_execute_circuits(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_controller, aer_circuits, noise_model, config)\n\u001b[1;32m    836\u001b[0m     \u001b[39mreturn\u001b[39;00m ret\n",
      "File \u001b[0;32m~/github/GridProjectHealth-Care/venv/lib/python3.10/site-packages/qiskit_aer/backends/backend_utils.py:435\u001b[0m, in \u001b[0;36mcpp_execute_circuits\u001b[0;34m(controller, aer_circuits, noise_model, config)\u001b[0m\n\u001b[1;32m    431\u001b[0m config\u001b[39m.\u001b[39mlibrary_dir \u001b[39m=\u001b[39m LIBRARY_DIR\n\u001b[1;32m    433\u001b[0m noise_model \u001b[39m=\u001b[39m noise_model\u001b[39m.\u001b[39mto_dict(serializable\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m) \u001b[39mif\u001b[39;00m noise_model \u001b[39melse\u001b[39;00m {}\n\u001b[0;32m--> 435\u001b[0m \u001b[39mreturn\u001b[39;00m controller\u001b[39m.\u001b[39;49mexecute(aer_circuits, noise_model, config)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Simulation device \"GPU\" is not supported on this system"
     ]
    }
   ],
   "source": [
    "then = time.time()\n",
    "runner()\n",
    "delta = time.time() - then\n",
    "print(f\"Image processed in: {delta: .6f}sec\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
